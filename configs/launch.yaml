repo:
  path: "./repos/java/spring-ai"
  commit: ""

language:
  name: "java"
  profile_dir: "configs/language"

llm:
  provider: "ollama"
  base_url: "http://localhost:11434/v1"
  model: "qwen2.5:7b"
  temperature: 0.2
  max_tokens: 10000
  timeout_sec: 180

core:
  seed: 42
  retrieval_top_k: 6
  max_context_chars: 16000
  max_items: 50

method_understanding:
  enabled: true
  max_methods: 5

question_answer:
  questions_per_method: 3
  max_questions: 20
  batch_size: 5
  embedding_model: "nomic-embed-text"
  user_questions_path: "configs/user_inputs/user_questions.yaml"
  build_embeddings_in_user_mode: true
  coverage:
    mode: "hybrid"                 # upstream | downstream | hybrid
    targets: {high: 0.8, mid: 0.15, hard: 0.05}
    intent_targets:
      how_to: 0.2
      config: 0.15
      flow: 0.15
      auth: 0.1
      error: 0.15
      deploy: 0.1
      impact: 0.05
      perf: 0.05
      consistency: 0.03
      compatibility: 0.02
      edge: 0.0
    labeler: "rule"
    templates_path: "configs/user_inputs/qa_templates.yaml"

design_questions:
  min_evidence_refs: 2
  use_method_profiles: true
  profiles_top_k: 20
  profiles_max_chars: 6000
  require_layer_coverage: true
  batch_size: 5
  max_questions: 20
  user_questions_path: "configs/user_inputs/design_questions.yaml"
  coverage:
    mode: "hybrid"
    targets: {high: 0.8, mid: 0.15, hard: 0.05}
    labeler: "rule"
    templates_path: "configs/user_inputs/design_templates.yaml"
  batching:
    enabled: true
    max_batches: 5
    diversity_hint: true

prompts:
  method_understanding: "configs/prompts/method_understanding/auto_method_understanding.txt"
  question_answer:
    question_generation: "configs/prompts/question_answer/auto_question_generation.txt"
    answer_generation: "configs/prompts/question_answer/auto_answer_generation.txt"
  design_questions_generation: "configs/prompts/design/auto_design_question_generation.txt"

artifacts:
  method_profiles_jsonl: "data/intermediate/method_profiles.jsonl"
  auto_method_understanding_rejected_jsonl: "data/intermediate/rejected/auto_method_understanding_rejected.jsonl"
  questions_jsonl: "data/intermediate/auto_questions/questions.jsonl"
  method_embeddings_jsonl: "data/intermediate/method_embeddings.jsonl"
  auto_qa_raw_jsonl: "data/intermediate/auto_qa_raw.jsonl"
  auto_answer_rejected_jsonl: "data/intermediate/rejected/auto_answer_rejected.jsonl"
  qa_clean_jsonl: "data/intermediate/clean/qa_clean.jsonl"
  design_questions_jsonl: "data/intermediate/auto_questions/design_questions_auto.jsonl"
  design_questions_rejected_jsonl: "data/intermediate/rejected/design_questions_auto_rejected.jsonl"
  design_questions_snapshot_jsonl: "data/intermediate/auto_questions/design_questions.jsonl"
  design_rejected_jsonl: "data/intermediate/rejected/design_rejected.jsonl"
  design_clean_jsonl: "data/intermediate/clean/design_clean.jsonl"
  coverage_report_json: "data/reports/coverage_report.json"

quality:
  gate_mode: "gate"
  write_clean: true
  allow_fallback_in_report: true
  fail_on_warnings: false
  trace_rules:
    mode: "warning"               # warning | reject
    scope: "all"                  # all | arch_design
    require_evidence_refs: false  # false=所有样本校验
    require_non_empty: true
    require_evidence_alignment: true
    min_observations: 1
    min_inferences: 1
    max_observations: 8
    max_inferences: 8
    max_assumptions: 5
  min_instruction_length: 10
  min_answer_length: 20
  max_answer_length: 6000

dedup:
  simhash_bits: 64
  max_hamming: 3

split:
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  group_by: "package"

safety:
  mode: "keep"            # drop | keep | sanitize
  blacklist_keywords:
    - "作为人工智能"
    - "无法访问"
    - "不具备"
    - "抱歉"

output:
  raw_dir: "data/raw/extracted"
  repo_meta_dir: "data/raw/repo_meta"
  intermediate_dir: "data/intermediate"
  final_dir: "data/final"
  reports_dir: "data/reports"
  qa_final_dir: "data/final/qa"
  design_final_dir: "data/final/design"

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/pipeline.log"
