这是一份为您专门定制的 checklist.md。它不仅涵盖了数据质量的要求，更侧重于评审“生成代码（Pipeline/Scripts）”的逻辑完备性，确保您的自动化流程能产出高标准的训练集。

📝 训练集生成流水线（Pipeline）评审清单
1. 宏观分布控制 (Distribution Control)
核心目标：确保生成逻辑不是随机的，而是由策略驱动的“按需分配”。

[ ] 配额逻辑校验：代码是否实现了 80% (简单) / 15% (中等) / 5% (困难) 的分类生成逻辑？

[ ] 难度判定因子：

[ ] 是否存在逻辑判断 module_span（跨文件/模块数量）？

[ ] 是否统计了 evidence_refs 的数量作为难度参考？

[ ] 是否包含对“隐含约束”或“反直觉逻辑”的定向 Prompt 注入？

[ ] 多样性采样：代码是否根据 question_type（解释/规则/操作/诊断/设计）进行了均衡采样，避免全是“解释类”题目？

[ ] 场景化注入：是否在 Prompt 中模拟了 20% 以上的模糊提问、指代提问（如“这段代码”、“那个接口”）？

2. 证据锚定与 Grounding (Grounding Integrity)
核心目标：确保每一条数据都有据可查，消灭幻觉。

[ ] 元数据提取：代码提取的 repo, commit_id, file_path, line_range 是否准确？（建议通过 AST 或正则二次校验）。

[ ] 上下文最小化逻辑：

[ ] 是否有逻辑剔除无关代码块（如 Import、无关注释）？

[ ] 是否实现了基于“依赖关系”或“调用链”的 Context 召回，而非简单的全文件填充？

[ ] Trace 锚定强制要求：在生成 Trace 的 Prompt 中，是否明确要求模型必须在每一步推导后标注 (File:L#Line)？

3. 推理链路质量 (Reasoning Trace Logic)
核心目标：让模型学会“决策过程”，而非单纯的结果展示。

[ ] 多步推理结构：代码生成的结构是否强制包含 Analysis -> Evidence -> Decision -> Result？

[ ] 设计类决策对比：

[ ] 生成逻辑中是否包含“反例对比”逻辑（即：为什么不采用其他方案）？

[ ] 是否关联了现有的架构约束（如：现有模块 X 已有类似实现）？

[ ] 逻辑自洽性校验：是否有自动化脚本检查推理 Trace 的最终结论与 answer 字段是否一致？

4. 健壮性与负样本 (Robustness & Negative Samples)
核心目标：训练模型学会“拒绝”与“纠错”。

[ ] 拒答逻辑生成：是否包含“证据不足”的生成场景（故意提供缺失关键信息的 Context）？

[ ] 纠错场景生成：是否包含“误导性问题”生成逻辑（用户问了错误的前提，模型需进行纠偏）？

[ ] 冲突处理逻辑：是否模拟了“代码实现与文档注释不一致”的冲突样本？

5. 工程质量与清洗 (Data Engineering)
核心目标：提高信噪比，确保进入训练集的数据是干净的。

[ ] 自动化过滤阈值：

[ ] 长度过滤：是否剔除了过短或过长的无效回答？

[ ] 关键词黑名单：是否剔除了包含“作为人工智能”、“无法访问”等废话的样本？

[ ] 语义去重：代码中是否包含 Embedding 相似度计算，以剔除高度重复的模板化样本？

[ ] 敏感信息脱敏：脚本是否自动识别并替换了 IP、Token、秘钥或具体人名？

6. 验证与闭环 (Verification & Feedback)
核心目标：构建持续改进的流水线。

[ ] LLM-as-a-Judge 接口：代码是否预留了调用更强模型（如 GPT-4o）进行自动评分的接口？

[ ] 报表输出：运行结束后是否能生成分布报告（各难度、各意图比例，各模块覆盖率）？

[ ] 回归机制：对于人工标记为 Bad Case 的样本，生成代码是否有逻辑进行定向微调或重生成？