目标对齐（Alignment）
样本的输入输出形式、语气、步骤、粒度，必须与线上真实使用场景高度一致：

用户会怎么问？（模糊问、指代问、带约束问、多轮追问）

你希望模型怎么答？（引用证据、给出结论、说明边界、给出可执行方案）

可验证正确（Verifiable Correctness）
训练样本的“正确性”最好能被自动或半自动验证，而不是靠主观感觉：

问答：答案能否从给定代码/文档片段直接推出？是否存在“看起来合理但仓库里并没有”的幻觉？

设计：方案是否与现有模块/依赖/约束一致？是否给出了接口、落地步骤、影响面？

覆盖充分且分布合理（Coverage & Distribution）
覆盖“常见问题 + 高价值长尾 + 容易出错的边界条件”，并且比例合理：

80% 高频真实需求（上手、调用、配置、流程、权限、错误码、部署、变更影响）

15% 中等复杂（跨模块链路、规则冲突、性能/一致性权衡）

5% 困难样本（反直觉、坑点、历史兼容、隐含约束）

高信噪比（High Signal-to-Noise）
模型从样本中学到的是“可泛化的模式”，而不是噪声：

问题清晰、上下文充足但不过载

答案结构稳定、步骤可复用

重复样本少、模板化但不僵硬

2) 单条样本应具有什么特点（核心清单）
A. 训练样本的“硬指标”（强烈建议作为准入门槛）

强 grounding：有证据、有引用定位

必须包含：repo、commit/版本、file_path、line_range、code_snippet（或文档原文片段）

答案中要能对上证据：至少在元数据里可回溯（答案正文可不必贴全文，但必须可追溯）

边界清晰：声明假设与适用范围

对业务规则类问题：写清“触发条件/前置校验/异常分支/权限条件/默认值”。

对设计类问题：写清“非目标/不做什么/与现有系统的兼容前提”。

可复现：上下文最小充分集（Minimal Sufficient Context）

不要把整个文件或整个仓库都塞进上下文。

只提供能支撑推理的必要片段（例如函数签名 + 关键分支 + 常量/配置 + 依赖接口）。

一致的输出规范（Schema Consistency）

同一类任务输出结构尽量稳定（如固定段落：结论→证据→步骤→注意事项）。

稳定结构能显著降低训练噪声，提高可控性。

B. 多样性与代表性（决定“泛化能力”的关键）

建议你用“覆盖维度”来强制采样，而不是靠随机：

问题类型维度

解释类：某函数/流程做什么，为什么这样做

规则类：什么条件下允许/拒绝/走哪个分支

操作类：如何接入、如何配置、如何迁移

诊断类：报错/异常如何定位与修复

变更影响：改动某处会影响哪些模块/测试/接口

设计类：新增需求如何落到现有架构（含权衡）

代码维度

覆盖不同语言/框架（如 Go/Java/Python/TS）

覆盖不同层次：API 层、领域层、基础设施层、配置/CI

覆盖不同复杂度：单函数 → 跨文件调用链 → 跨服务边界（如有）

难度维度

直接证据（单处即可回答）

多证据组合（需要跨文件拼起来）

冲突处理（文档与实现不一致、旧逻辑兼容）

反例/负例维度（非常重要）

“看起来像，但不是”：相似函数、旧版本逻辑、过期文档

让模型学会拒答/补充信息：证据不足时如何回应（这比硬编答案更重要）

3) 关于“推理 trace”：什么样的 trace 才是高质量、可用于训练的

你在任务里要求“推理过程/trace”。从数据质量角度，好的 trace 不是冗长的思维独白，而是可审计、可对齐证据的决策记录。

推荐的 trace 形态（可训练、可控、可审计）

Evidence-anchored steps（证据锚定步骤）
每一步都指向证据片段：

Step 1：从 file:A#L10-40 确认触发条件

Step 2：从 file:B#L80-120 确认权限校验

Step 3：合并得到最终规则与例外

Decision log（设计决策日志）
对设计类尤其有效：

决策：选择方案 A（例如事件驱动）

原因：现有模块 X 已有事件总线；满足一致性要求；改动面最小

代价：引入最终一致；需要补偿机制

证据：引用仓库已有模式与接口位置

不推荐的 trace（训练噪声大、难控）

大段“内心独白式”推理，缺少证据锚定

复述题目或复述代码，不产生新增信息

用“因为我觉得/一般来说”替代仓库事实